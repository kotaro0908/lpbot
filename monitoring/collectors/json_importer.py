#!/usr/bin/env python3
"""
LP BOTç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  - JSONãƒ­ã‚°ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼
JSONãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿
"""

import json
import sqlite3
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent.parent))

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
DB_PATH = Path(__file__).parent.parent / "lpbot.db"
LOGS_DIR = Path(__file__).parent.parent.parent  # /root/lpbot/


class JSONLogImporter:
    """JSONãƒ­ã‚°ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹"""

    def __init__(self, db_path=DB_PATH):
        self.db_path = db_path
        self.conn = None
        self.imported_count = 0
        self.skipped_count = 0
        self.error_count = 0

    def connect(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’æœ‰åŠ¹åŒ–
        self.conn.execute("PRAGMA foreign_keys = ON")

    def close(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ‡æ–­"""
        if self.conn:
            self.conn.close()

    def get_log_files(self, days_back=7) -> List[Path]:
        """å¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        log_files = []

        # ä»Šæ—¥ã‹ã‚‰éå»Næ—¥åˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        for i in range(days_back):
            date = datetime.now() - timedelta(days=i)
            filename = f"logs_{date.strftime('%Y-%m-%d')}.json"
            filepath = LOGS_DIR / filename

            if filepath.exists():
                log_files.append(filepath)

        # archiveãƒ•ã‚©ãƒ«ãƒ€ã‚‚ç¢ºèª
        archive_dir = LOGS_DIR / "archive"
        if archive_dir.exists():
            for file in archive_dir.glob("logs_*.json"):
                log_files.append(file)

        return sorted(log_files)

    def parse_log_line(self, line: str) -> Dict[str, Any]:
        """ãƒ­ã‚°è¡Œã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            # ç©ºè¡Œã‚„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
            line = line.strip()
            if not line or line.startswith('#'):
                return None

            return json.loads(line)
        except json.JSONDecodeError as e:
            print(f"âš ï¸  JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def check_duplicate(self, table: str, timestamp: str, unique_fields: Dict) -> bool:
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç§’å˜ä½ã«ä¸¸ã‚ã¦æ¯”è¼ƒï¼ˆãƒŸãƒªç§’ã®é•ã„ã‚’ç„¡è¦–ï¼‰
        timestamp_seconds = timestamp.split('.')[0] if '.' in timestamp else timestamp

        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ™ãƒ¼ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        query = f"SELECT 1 FROM {table} WHERE datetime(timestamp, 'start of second') = datetime(?, 'start of second')"
        params = [timestamp_seconds]

        # è¿½åŠ ã®ä¸€æ„æ€§ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        for field, value in unique_fields.items():
            query += f" AND {field} = ?"
            params.append(value)

        cursor = self.conn.execute(query + " LIMIT 1", params)
        return cursor.fetchone() is not None

    def import_rebalance(self, data: Dict):
        """ãƒªãƒãƒ©ãƒ³ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            unique_fields = {
                'reason': data.get('reason'),
                'old_nft_id': data.get('old_nft_id'),
                'new_nft_id': data.get('new_nft_id')
            }

            if self.check_duplicate('rebalance_history', data['timestamp'], unique_fields):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO rebalance_history (timestamp, reason, old_nft_id, new_nft_id,
                                                             old_tick_lower, old_tick_upper, new_tick_lower,
                                                             new_tick_upper,
                                                             price_at_rebalance, estimated_amount, actual_amount,
                                                             swap_executed, tx_hash, success, error_message)
                              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('reason', 'unknown'),
                                  data.get('old_nft_id'),
                                  data.get('new_nft_id'),
                                  data.get('old_tick_lower'),
                                  data.get('old_tick_upper'),
                                  data.get('new_tick_lower'),
                                  data.get('new_tick_upper'),
                                  data.get('price_at_rebalance'),
                                  data.get('estimated_amount'),
                                  data.get('actual_amount'),
                                  1 if data.get('swap_executed', False) else 0,
                                  data.get('tx_hash'),
                                  1 if data.get('success', True) else 0,
                                  data.get('error_message')
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ ãƒªãƒãƒ©ãƒ³ã‚¹ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_swap(self, data: Dict):
        """SWAPã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if self.check_duplicate('swap_history', data['timestamp'], {}):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO swap_history (timestamp, from_token, to_token, amount,
                                                        swap_direction, tx_hash, success, error_message)
                              VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('from_token'),
                                  data.get('to_token'),
                                  data.get('amount'),
                                  data.get('swap_direction'),
                                  data.get('tx_hash'),
                                  1 if data.get('success', True) else 0,
                                  data.get('error_message')
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ SWAPã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_fund_change(self, data: Dict):
        """è³‡é‡‘å¤‰å‹•ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if self.check_duplicate('fund_changes', data['timestamp'], {}):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO fund_changes (timestamp, change_type, amount_usd,
                                                        eth_balance, weth_balance, usdc_balance,
                                                        total_value_usd, trigger_action)
                              VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('change_type'),
                                  data.get('amount_usd'),
                                  data.get('eth_balance'),
                                  data.get('weth_balance'),
                                  data.get('usdc_balance'),
                                  data.get('total_value_usd'),
                                  data.get('trigger_action')
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ è³‡é‡‘å¤‰å‹•ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_gas_retry(self, data: Dict):
        """ã‚¬ã‚¹ãƒªãƒˆãƒ©ã‚¤ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            unique_fields = {
                'function_name': data.get('function_name'),
                'attempt': data.get('attempt')
            }

            if self.check_duplicate('gas_retry_history', data['timestamp'], unique_fields):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO gas_retry_history (timestamp, function_name, attempt,
                                                             gas_limit, gas_multiplier, success)
                              VALUES (?, ?, ?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('function_name'),
                                  data.get('attempt'),
                                  data.get('gas_limit'),
                                  data.get('gas_multiplier'),
                                  1 if data.get('success', False) else 0
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ ã‚¬ã‚¹ãƒªãƒˆãƒ©ã‚¤ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_lp_creation(self, data: Dict):
        """LPä½œæˆã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            unique_fields = {'tx_hash': data.get('tx_hash')} if data.get('tx_hash') else {}

            if self.check_duplicate('lp_creation_history', data['timestamp'], unique_fields):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO lp_creation_history (timestamp, tx_hash, gas_used, events,
                                                               tick_lower, tick_upper, amount_weth, amount_usdc,
                                                               success, error_message)
                              VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('tx_hash'),
                                  data.get('gas_used'),
                                  data.get('events'),
                                  data.get('tick_lower'),
                                  data.get('tick_upper'),
                                  data.get('amount_weth'),
                                  data.get('amount_usdc'),
                                  1 if data.get('success', True) else 0,
                                  data.get('error', data.get('error_message'))
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ LPä½œæˆã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_system_log(self, data: Dict):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if self.check_duplicate('system_logs', data['timestamp'], {}):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO system_logs (timestamp, log_level, function_name,
                                                       message, execution_time_ms, error_details)
                              VALUES (?, ?, ?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('log_level', 'INFO'),
                                  data.get('function_name'),
                                  data.get('message'),
                                  data.get('execution_time_ms'),
                                  data.get('error_details')
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_monitoring_cycle(self, data: Dict):
        """ç›£è¦–ã‚µã‚¤ã‚¯ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        try:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            unique_fields = {'cycle': data.get('cycle')}

            if self.check_duplicate('monitoring_cycles', data['timestamp'], unique_fields):
                self.skipped_count += 1
                return

            # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
            self.conn.execute("""
                              INSERT INTO monitoring_cycles (timestamp, cycle, tracked_nfts, status)
                              VALUES (?, ?, ?, ?)
                              """, (
                                  data['timestamp'],
                                  data.get('cycle'),
                                  json.dumps(data.get('tracked_nfts', [])),
                                  data.get('status', 'started')
                              ))

            self.imported_count += 1

        except Exception as e:
            print(f"âŒ ç›£è¦–ã‚µã‚¤ã‚¯ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.error_count += 1

    def import_log_entry(self, entry: Dict):
        """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¿ã‚¤ãƒ—åˆ¥æŒ¯ã‚Šåˆ†ã‘ï¼‰"""
        if not entry or 'type' not in entry:
            return

        log_type = entry['type']

        # ã‚¿ã‚¤ãƒ—åˆ¥ã®å‡¦ç†
        if log_type == 'rebalance':
            self.import_rebalance(entry)
        elif log_type == 'swap':
            self.import_swap(entry)
        elif log_type == 'fund_change':
            self.import_fund_change(entry)
        elif log_type == 'gas_retry':
            self.import_gas_retry(entry)
        elif log_type == 'lp_creation':
            self.import_lp_creation(entry)
        elif log_type == 'system':
            self.import_system_log(entry)
        elif log_type == 'monitoring_cycle':
            self.import_monitoring_cycle(entry)
        else:
            # ãã®ä»–ã®ã‚¿ã‚¤ãƒ—ã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°ã¨ã—ã¦è¨˜éŒ²
            entry['log_level'] = 'INFO'
            entry['message'] = f"Unknown log type: {log_type}"
            self.import_system_log(entry)

    def import_file(self, filepath: Path):
        """ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã§ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
        print(f"\nğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†: {filepath.name}")

        file_imported = 0
        file_skipped = 0
        file_errors = 0

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    entry = self.parse_log_line(line)
                    if entry:
                        before_imported = self.imported_count
                        before_skipped = self.skipped_count
                        before_errors = self.error_count

                        self.import_log_entry(entry)

                        # ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã®çµ±è¨ˆæ›´æ–°
                        if self.imported_count > before_imported:
                            file_imported += 1
                        elif self.skipped_count > before_skipped:
                            file_skipped += 1
                        elif self.error_count > before_errors:
                            file_errors += 1

            print(f"   âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {file_imported}ä»¶")
            print(f"   â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {file_skipped}ä»¶ï¼ˆé‡è¤‡ï¼‰")
            if file_errors > 0:
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {file_errors}ä»¶")

        except Exception as e:
            print(f"   âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def update_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°"""
        self.conn.execute("""
            INSERT OR REPLACE INTO metadata (key, value, updated_at)
            VALUES ('last_import_at', ?, CURRENT_TIMESTAMP)
        """, (datetime.now().isoformat(),))

        self.conn.execute("""
            INSERT OR REPLACE INTO metadata (key, value, updated_at)
            VALUES ('total_imported', ?, CURRENT_TIMESTAMP)
        """, (str(self.imported_count),))

    def update_daily_performance(self):
        """æ—¥æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é›†è¨ˆæ›´æ–°"""
        print("\nğŸ“Š æ—¥æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é›†è¨ˆä¸­...")

        # å„æ—¥ä»˜ã®ãƒªãƒãƒ©ãƒ³ã‚¹å›æ•°ã‚’é›†è¨ˆ
        self.conn.execute("""
            INSERT OR REPLACE INTO daily_performance (
                date, rebalance_count, error_count, success_rate
            )
            SELECT 
                DATE(timestamp) as date,
                COUNT(*) as rebalance_count,
                SUM(CASE WHEN success = 0 THEN 1 ELSE 0 END) as error_count,
                AVG(CASE WHEN success = 1 THEN 1.0 ELSE 0.0 END) * 100 as success_rate
            FROM rebalance_history
            GROUP BY DATE(timestamp)
        """)

        # SWAPå›æ•°ã‚’æ›´æ–°
        self.conn.execute("""
                          UPDATE daily_performance
                          SET swap_count = (SELECT COUNT(*)
                                            FROM swap_history
                                            WHERE DATE (swap_history.timestamp) = daily_performance.date
                              )
                          """)

        print("   âœ… æ—¥æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°å®Œäº†")

    def run_import(self, days_back=7):
        """ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ"""
        print(f"\nğŸš€ JSONãƒ­ã‚°ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹")
        print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {self.db_path}")
        print(f"ğŸ“… å¯¾è±¡æœŸé–“: éå»{days_back}æ—¥é–“")

        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            self.connect()

            # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
            log_files = self.get_log_files(days_back)
            print(f"\nğŸ“ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(log_files)}å€‹")

            if not log_files:
                print("âš ï¸  ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return

            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            for filepath in log_files:
                self.import_file(filepath)
                # ã‚³ãƒŸãƒƒãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ï¼‰
                self.conn.commit()

            # æ—¥æ¬¡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°
            self.update_daily_performance()

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            self.update_metadata()

            # æœ€çµ‚ã‚³ãƒŸãƒƒãƒˆ
            self.conn.commit()

            # çµæœè¡¨ç¤º
            print(f"\nğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœ:")
            print(f"   âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {self.imported_count}ä»¶")
            print(f"   â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {self.skipped_count}ä»¶ï¼ˆé‡è¤‡ï¼‰")
            if self.error_count > 0:
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {self.error_count}ä»¶")

            # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
            self.show_statistics()

            print("\nâœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†!")

        except Exception as e:
            print(f"\nâŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            if self.conn:
                self.conn.rollback()
            raise
        finally:
            self.close()

    def show_statistics(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º"""
        print("\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:")

        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä»¶æ•°
        tables = [
            'rebalance_history',
            'swap_history',
            'fund_changes',
            'gas_retry_history',
            'lp_creation_history',
            'system_logs',
            'monitoring_cycles'
        ]

        for table in tables:
            cursor = self.conn.execute(f"SELECT COUNT(*) FROM {table}")
            count = cursor.fetchone()[0]
            print(f"   {table}: {count}ä»¶")

        # æœ€æ–°ã®ãƒªãƒãƒ©ãƒ³ã‚¹
        cursor = self.conn.execute("""
                                   SELECT timestamp, old_nft_id, new_nft_id
                                   FROM rebalance_history
                                   ORDER BY timestamp DESC
                                       LIMIT 1
                                   """)
        latest = cursor.fetchone()
        if latest:
            print(f"\n   æœ€æ–°ãƒªãƒãƒ©ãƒ³ã‚¹: {latest['timestamp']}")
            print(f"   NFT: {latest['old_nft_id']} â†’ {latest['new_nft_id']}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='JSONãƒ­ã‚°ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ')
    parser.add_argument('--days', type=int, default=7, help='éå»ä½•æ—¥åˆ†ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7ï¼‰')
    parser.add_argument('--all', action='store_true', help='å…¨ã¦ã®åˆ©ç”¨å¯èƒ½ãªãƒ­ã‚°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ')

    args = parser.parse_args()

    # ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼å®Ÿè¡Œ
    importer = JSONLogImporter()

    if args.all:
        importer.run_import(days_back=365)  # å®Ÿè³ªçš„ã«å…¨ã¦
    else:
        importer.run_import(days_back=args.days)


if __name__ == "__main__":
    main()